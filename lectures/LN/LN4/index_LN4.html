<!DOCTYPE html>
<html lang="es" id="html-root">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Redes Neuronales Biomoleculares - EBCP Latam 2025</title>

    <!-- Favicon -->
    <link rel="icon" type="image/svg+xml" href="../../../images/bacteria favicon.svg">

    <link rel="stylesheet" href="../../../static/custom.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- MathJax para matemáticas -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
        window.MathJax = {
            tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            displayMath: [['$$', '$$'], ['\\[', '\\]']]
            },
            svg: {
                fontCache: 'global'
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <!-- Prism.js para sintaxis highlighting -->
    <link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/themes/prism-tomorrow.min.css" rel="stylesheet">
    
</head>

<body>
    <!-- Header - exactamente igual a tu index -->
    <header class="header">
        <nav class="navbar">
            <div class="nav-brand">
                <img src="../../../images/logobacteria.svg" alt="EBCP Latam Logo" class="nav-logo">
                <span class="brand-text">EBCP Latam 2025</span>
            </div>
            <div class="nav-links">
                <a href="../../../index.html" data-es="Inicio" data-en="Home">Inicio</a>
                <a href="../../../lectures.html" data-es="Lectures" data-en="Lectures">Lectures</a>
                <a href="../../../about.html" data-es="Sobre Nosotros" data-en="About Us">Sobre Nosotros</a>
                <a href="https://github.com/polarbio/wsynbio-2025" target="_blank">GitHub</a>
                
                <!-- Language Toggle -->
                <div class="language-toggle">
                    <button class="lang-btn active" data-lang="es">ESP</button>
                    <button class="lang-btn" data-lang="en">EN</button>
                </div>
            </div>
        </nav>
    </header>

    <!-- Notebook Section -->
    <section class="notebook-section">
        <div class="notebook-container">

            <!-- Header del notebook -->
            <div class="notebook-header-TR">
                <h1 class="notebook-title"
                    data-es="Redes Neuronales Biomoleculares"
                    data-en="Biomolecular Neural Networks">
                    Redes Neuronales Biomoleculares
                </h1>
                <p class="notebook-subtitle"
                   data-es="2025 Workshop en Modelamiento de Sistemas Biológicos"
                   data-en="2025 Workshop on Biological Systems Modeling">
                    2025 Workshop en Modelamiento de Sistemas Biológicos
                </p>
                <div class="notebook-meta">
                    <div data-es="Autores: Jennyfer Arismendiz Millones y Bsc. Frank Britto Bisso | Revisado por: PhD. Christian Cuba Samaniego"
                         data-en="Authors: Jennyfer Arismendiz Millones and Bsc. Frank Britto Bisso | Reviewed by: PhD. Christian Cuba Samaniego">
                        Autores: Jennyfer Arismendiz Millones y Bsc. Frank Britto Bisso | Revisado por: PhD. Christian Cuba Samaniego
                    </div>
                    <div data-es="Última fecha de modificación: 12 de Julio, 2025"
                         data-en="Last modified: July 12, 2025">
                        Última fecha de modificación: 12 de Julio, 2025
                    </div>
                </div>
            </div>

            <!-- Contenido del notebook -->
            
            <div class="cell cell-markdown">
                
                <p data-es="Las redes neuronales artificiales han revolucionado la computación moderna gracias a su capacidad de aprender patrones complejos y realizar tareas de clasificación o predicción. Sin embargo, más allá del silicio, recientes avances en biología sintética han comenzado a explorar cómo implementar redes neuronales dentro de sistemas moleculares para mejorar la capacidad computacional de células (<a style='color: var(--dark-purple);' href='https://ieeexplore.ieee.org/document/9030122/'>Moorman et al, 2021</a>). En esta lección estudiaremos cómo modelar y diseñar clasificadores lineales y no lineales utilizando circuitos moleculares que operan como redes neuronales, enfocandonos en el mecanismo de secuestramiento molecular."
                   data-en="Artificial neural networks have revolutionized modern computing thanks to their ability to learn complex patterns and perform classification or prediction tasks. However, beyond silicon, recent advances in synthetic biology have begun to explore how to implement neural networks within molecular systems to enhance the computational capacity of cells (<a style='color: var(--dark-purple);' href='https://ieeexplore.ieee.org/document/9030122/'>Moorman et al, 2021</a>). In this lesson, we will study how to model and design linear and nonlinear classifiers using molecular circuits that operate as neural networks, focusing on the mechanism of molecular sequestration.">
                    Las redes neuronales artificiales han revolucionado la computación moderna gracias a su capacidad de aprender patrones complejos y realizar tareas de clasificación o predicción. Sin embargo, más allá del silicio, recientes avances en biología sintética han comenzado a explorar cómo implementar redes neuronales dentro de sistemas moleculares para mejorar la capacidad computacional de células (<a style='color: var(--dark-purple);' href='https://ieeexplore.ieee.org/document/9030122/'>Moorman et al, 2021</a>). En esta lección estudiaremos cómo modelar y diseñar clasificadores lineales y no lineales utilizando circuitos moleculares que operan como redes neuronales, enfocandonos en el mecanismo de secuestramiento molecular.
                </p>

                <h2 style="color: var(--dark-purple);" data-es="Clasificadores Lineales"
                    data-en="Linear Classifiers">
                    Clasificadores Lineales
                </h2>

                <p data-es="Una función de activación es una función matemática que describe si una neurona se activará o no, según la intensidad de la señal que recibe. Podemos imaginarlo como un interruptor de luz que se enciende solo si la señal supera cierta intensidad mínima. A esta intensidad mínima se le denomina <strong>valor umbral</strong>: si la señal es menor, no habrá respuesta; pero si es mayor, la neurona responderá. Una de las funciones más utilizadas es la Rectified Linear Unit, o ReLU, descrita por la siguiente ecuación:"
                   data-en="An activation function is a mathematical function that determines whether a neuron will activate or not, depending on the strength of the signal it receives. We can imagine it like a light switch that turns on only if the signal exceeds a certain minimum intensity. This minimum intensity is called the <strong>threshold value</strong>: if the signal is lower, there will be no response; but if it is higher, the neuron will respond. One of the most commonly used functions is the Rectified Linear Unit, or ReLU, described by the following equation:">
                   Una función de activación es una función matemática que describe si una neurona se activará o no, según la intensidad de la señal que recibe. Podemos imaginarlo como un interruptor de luz que se enciende solo si la señal supera cierta intensidad mínima. A esta intensidad mínima se le denomina <strong>valor umbral</strong>: si la señal es menor, no habrá respuesta; pero si es mayor, la neurona responderá. Una de las funciones más utilizadas es la Rectified Linear Unit, o ReLU, descrita por la siguiente ecuación:
                </p>

                <div class="math-block">
                    $$\begin{align}
                   \text{ReLU}(x) = \max(0, x)
                    \end{align}$$
                </div>

                <p data-es="En este contexto, para implementar las redes neuronales biomoleculares, necesitaremos un circuito biológico tal que la relación entre sus entradas y salidas exhiba también una forma de definir un valor umbral. Es decir, que su mapa de entradas y salidas exhiba <strong>thresholding</strong>. Hemos ya estudiado un mecanismo que nos permite obtener este tipo de comportamiento: el secuestramiento molecular."
                   data-en="In this context, to implement biomolecular neural networks, we will need a biological circuit such that the relationship between its inputs and outputs also exhibits a way to define a threshold value. That is, its input-output map must exhibit <strong>thresholding</strong>. We have already studied a mechanism that allows us to achieve this type of behavior: molecular sequestration.">
                   En este contexto, para implementar las redes neuronales biomoleculares, necesitaremos un circuito biológico tal que la relación entre sus entradas y salidas exhiba también una forma de definir un valor umbral. Es decir, que su mapa de entradas y salidas exhiba <strong>thresholding</strong>. Hemos ya estudiado un mecanismo que nos permite obtener este tipo de comportamiento: el secuestramiento molecular.
                </p>

                <p data-es="Consideremos una ligera variante del sistema que estudiamos en la Lecture Note #1. Sean $Y$ y $Z$ dos genes que producen proteinas del mismo nombre en respuesta a ciertas entradas $X_1$ y $X_2$ que controlan dicha producción (e.g., moléculas pequeñas en un promotor inducible). Las proteinas $Y$ y $Z$ pueden interactuar entre ellas por secuestramiento molecular. Podemos describir este sistema con las siguientes reacciones químicas:"
                   data-en="Let us consider a slight variation of the system we studied in Lecture Note #1. Let $Y$ and $Z$ be two genes that produce proteins of the same name in response to certain inputs $X_1$ and $X_2$ that control their production (e.g., small molecules in an inducible promoter). The proteins $Y$ and $Z$ can interact with each other through molecular sequestration. We can describe this system with the following chemical reactions:">
                   Consideremos una ligera variante del sistema que estudiamos en la Lecture Note #1. Sean $Y$ y $Z$ dos genes que producen proteinas del mismo nombre en respuesta a ciertas entradas $X_1$ y $X_2$ que controlan dicha producción (e.g., moléculas pequeñas en un promotor inducible). Las proteinas $Y$ y $Z$ pueden interactuar entre ellas por secuestramiento molecular. Podemos describir este sistema con las siguientes reacciones químicas:
                </p>

                <div class="math-block">
                    $$\begin{align}
                   X_1 &\xrightarrow{w_1} Y && Y \xrightarrow{\delta} \emptyset && \text{Producción and degradación de $Y$}\\
                    X_2 &\xrightarrow{w_2} Z && Z \xrightarrow{\delta} \emptyset && \text{Producción y degradación de $Z$}\\
                    Y + Z &\overset{a}{\underset{d}{\leftrightarrows}} C && C \xrightarrow{\delta} \emptyset && \text{Secuestramiento y degradación de $C$}
                    \end{align}$$
                </div>

                <p data-es="Utilizando la ley de acción de masas, podemos modelar dichas reacciones químicas con las siguientes ecuaciones diferenciales:"
                   data-en="Using the law of mass action, we can model these chemical reactions with the following differential equations:">
                  Utilizando la ley de acción de masas, podemos modelar dichas reacciones químicas con las siguientes ecuaciones diferenciales:
                </p>

                <div class="math-block">
                    $$\begin{eqnarray}
                   \frac{d}{dt}y &=& x_1 w_1 - \delta y + dc - ayz \\
                    \frac{d}{dt}        z &=& x_2 w_2 - \delta z + dc - ayz \\
                    \frac{d}{dt}        c &=& ayz - dc - \delta c
                    \end{eqnarray}$$
                </div>

                <p data-es="Recordemos las ecuaciones de conservación de masa ($y^T = y + c$ y $z^T = z + c$), de modo que en estado estacionario, obtuvimos la siguiente expresión para $\bar y$,"
                   data-en="Let us recall the mass conservation equations ($y^T = y + c$ and $z^T = z + c$), so that at steady state, we obtained the following expression for $\bar y$:">
                  Recordemos las ecuaciones de conservación de masa ($y^T = y + c$ y $z^T = z + c$), de modo que en estado estacionario, obtuvimos la siguiente expresión para $\bar y$,
                </p>

                <div class="math-block">
                    $$\begin{eqnarray}
                   \bar y = \frac{1}{2} \left [ (x_1w_1 - x_2w_2 - K) + \sqrt{(x_1w_1 - x_2w_2 - K)^2 + 4Kx_1w_1} \right ]
                    \end{eqnarray}$$
                </div>

                <p data-es="Si ahora consideramos un régimen donde el secuestramiento es muy rápido, en el límite obtendremos"
                   data-en="If we now consider a regime where sequestration is very fast, in the limit we obtain:">
                  Si ahora consideramos un régimen donde el secuestramiento es muy rápido, en el límite obtendremos
                </p>

                <div class="math-block">
                    $$\begin{eqnarray}
                   \lim_{K \to 0} \bar y = \frac{1}{2} \left ( \frac{x_1w_1 - x_2w_2}{\delta} - \frac{|x_1w_1 - x_2w_2|}{\delta}\right )
                    \end{eqnarray}$$
                </div>

                <p data-es="Podemos reescribir esta ecuación como"
                   data-en="We can rewrite this equation as:">
                  Podemos reescribir esta ecuación como
                </p>

                <div class="math-block">
                    $$\begin{eqnarray}
                   \lim_{K \to 0} \bar y = \frac{1}{\delta} \max (0, x_1 w_1 - x_2 w_2)
                    \end{eqnarray}$$
                </div>
                
            </div>

            <div class="cell cell-output" style="margin-bottom: 0.5rem; text-align: center;">
            <!-- Versión en español -->
                <iframe class="lang-img" data-lang="es"
                    src="Figura 1_LN4_esp.html"
                    width="100%" height="275"
                    style="border:none; display: block;"></iframe>

                <!-- Versión en inglés -->
                <iframe class="lang-img" data-lang="en"
                    src="Figura 1_LN4_en.html"
                    width="100%" height="275"
                    style="border:none; display: none;"></iframe>
            </div>


            <div class="cell cell-markdown">

                <p data-es="A la izquierda de la Figura 1, observamos el valor de $\bar y$ para un valor muy pequeño de $K$ y diferentes valores de $x_1$ y $x_2$. Esta respuesta se asemeja a un clasificador lineal, donde la línea recta que divide entre una salida nula y una diferente a zero se denomina <strong>frontera de decisión</strong>. A la derecha de la Figura 1, observamos que la transición se da en $x_1 w_1 = x_2 w_2$, el cual define el valor umbral. Por este comportamiento, y dada la ecuación anterior, confirmamos que la reacción de secuestramiento se comporta como una neurona! Por notación, si nos referimos a una única neurona, esta recibirá el nombre de <strong>perceptron</strong>."
                   data-en="On the left of Figure 1, we observe the value of $\bar y$ for a very small value of $K$ and different values of $x_1$ and $x_2$. This response resembles a linear classifier, where the straight line dividing between a zero output and a non-zero output is called the <strong>decision boundary</strong>. On the right of Figure 1, we observe that the transition occurs at $x_1 w_1 = x_2 w_2$, which defines the threshold value. Due to this behavior, and given the previous equation, we confirm that the sequestration reaction behaves like a neuron! For notation purposes, when referring to a single neuron, it will be called a <strong>perceptron</strong>.">
                   A la izquierda de la Figura 1, observamos el valor de $\bar y$ para un valor muy pequeño de $K$ y diferentes valores de $x_1$ y $x_2$. Esta respuesta se asemeja a un clasificador lineal, donde la línea recta que divide entre una salida nula y una diferente a zero se denomina <strong>frontera de decisión</strong>. A la derecha de la Figura 1, observamos que la transición se da en $x_1 w_1 = x_2 w_2$, el cual define el valor umbral. Por este comportamiento, y dada la ecuación anterior, confirmamos que la reacción de secuestramiento se comporta como una neurona! Por notación, si nos referimos a una única neurona, esta recibirá el nombre de <strong>perceptron</strong>.
                </p>

                <p data-es="Como vimos en nuestra ecuación anterior, este comportamiento se da cuando la tasa de secuestramiento es muy alta (o, equivalentemente, cuando la constante de disociación es muy baja). Nos debemos preguntar entonces, ¿qué ocurre con nuestro clasificador si relajamos esta condición?"
                   data-en="As we saw in our previous equation, this behavior occurs when the sequestration rate is very high (or, equivalently, when the dissociation constant is very low). We must then ask ourselves: what happens to our classifier if we relax this condition?">
                   Como vimos en nuestra ecuación anterior, este comportamiento se da cuando la tasa de secuestramiento es muy alta (o, equivalentemente, cuando la constante de disociación es muy baja). Nos debemos preguntar entonces, ¿qué ocurre con nuestro clasificador si relajamos esta condición?
                </p>

            </div>

            <div class="cell cell-output" style="margin-bottom: 0.5rem; text-align: center;">
            <!-- Versión en español -->
                <iframe class="lang-img" data-lang="es"
                    src="Figura 2_LN4_esp.html"
                    width="100%" height="250"
                    style="border:none; display: block;"></iframe>

                <!-- Versión en inglés -->
                <iframe class="lang-img" data-lang="en"
                    src="Figura 2_LN4_en.html"
                    width="100%" height="250"
                    style="border:none; display: none;"></iframe>
            </div>


            <div class="cell cell-markdown">

                <h3 data-es="¿Cómo ajustar la frontera de decisión?"
                    data-en="How to adjust the decision boundary?">
                    ¿Cómo ajustar la frontera de decisión?
                </h3>

                <p data-es="Bajo el mismo argumento utilizando anteriormente, podemos generalizar la respuesta de nuestra reacción de secuestramiento molecular de la siguiente forma,"
                   data-en="Using the same argument as before, we can generalize the response of our molecular sequestration reaction as follows:">
                   Bajo el mismo argumento utilizando anteriormente, podemos generalizar la respuesta de nuestra reacción de secuestramiento molecular de la siguiente forma,
                </p>

                <div class="math-block">
                    $$\begin{eqnarray}
                    \lim_{K \to 0} \bar y = \frac{1}{\delta} \max (0, \sum_i x_i w_i - \sum_j x_j w_j)
                    \end{eqnarray}$$
                </div>

                <p data-es="En otras palabras, la salida estará dada por la resta entre el producto de las entradas $X_i$ que producen la especies $Y$ a una tasa $w_i$, y las entradas $X_j$ que producen la especie $Z$ a una tasa $w_j$. Es importante reconocer que <strong>ni las concentraciones ni las tasas de producción son negativas</strong>. El signo negativo asociado a ciertas entradas se da por la dinámica de la reacción de secuestramiento. Siguiendo esta lógica, si invertimos el orden de las entradas y evaluamos la salida $\bar y$, obtendremos también una decisión invertida."
                   data-en="In other words, the output will be given by the difference between the product of the inputs $X_i$ that produce species $Y$ at a rate $w_i$, and the inputs $X_j$ that produce species $Z$ at a rate $w_j$. It is important to recognize that <strong>neither the concentrations nor the production rates are negative</strong>. The negative sign associated with certain inputs arises from the dynamics of the sequestration reaction. Following this logic, if we reverse the order of the inputs and evaluate the output $\bar y$, we will also obtain an inverted decision.">
                   En otras palabras, la salida estará dada por la resta entre el producto de las entradas $X_i$ que producen la especies $Y$ a una tasa $w_i$, y las entradas $X_j$ que producen la especie $Z$ a una tasa $w_j$. Es importante reconocer que <strong>ni las concentraciones ni las tasas de producción son negativas</strong>. El signo negativo asociado a ciertas entradas se da por la dinámica de la reacción de secuestramiento. Siguiendo esta lógica, si invertimos el orden de las entradas y evaluamos la salida $\bar y$, obtendremos también una decisión invertida.
                </p>

            </div>

            <div class="cell cell-output" style="margin-bottom: 0.5rem; text-align: center;">
            <!-- Versión en español -->
                <iframe class="lang-img" data-lang="es"
                    src="Figura 3_LN4_esp.html"
                    width="100%" height="225"
                    style="border:none; display: block;"></iframe>

                <!-- Versión en inglés -->
                <iframe class="lang-img" data-lang="en"
                    src="Figura 3_LN4_esp.html"
                    width="100%" height="225"
                    style="border:none; display: none;"></iframe>
            </div>

            <div class="cell cell-markdown">

                <p data-es="Si evaluamos nuevamente la ecuación para $\bar y$, nos daremos cuenta de una estrategia para cambiar la frontera de decisión: ajustar los pesos $w_i$ y $w_j$. Experimentalmente, como estos están dados por las tasas de producción de cada especie, ajustar los pesos implicaría cambiar la tasa de transcripción y/o traslación (<a style='color: var(--dark-purple);' href='https://www.biorxiv.org/content/10.1101/2025.05.16.654484v1'>Nakamura et al, 2025</a>). Simulemos este caso cambiando los valores de $w_1$ y $w_2$."
                   data-en="If we evaluate the equation for $\bar y$ again, we will realize a strategy to change the decision boundary: adjusting the weights $w_i$ and $w_j$. Experimentally, since these are determined by the production rates of each species, adjusting the weights would involve changing the transcription and/or translation rate (<a style='color: var(--dark-purple);' href='https://www.biorxiv.org/content/10.1101/2025.05.16.654484v1'>Nakamura et al, 2025</a>). Let us simulate this case by changing the values of $w_1$ and $w_2$.">
                   Si evaluamos nuevamente la ecuación para $\bar y$, nos daremos cuenta de una estrategia para cambiar la frontera de decisión: ajustar los pesos $w_i$ y $w_j$. Experimentalmente, como estos están dados por las tasas de producción de cada especie, ajustar los pesos implicaría cambiar la tasa de transcripción y/o traslación (<a style='color: var(--dark-purple);' href='https://www.biorxiv.org/content/10.1101/2025.05.16.654484v1'>Nakamura et al, 2025</a>). Simulemos este caso cambiando los valores de $w_1$ y $w_2$.
                </p>

                <p data-es="Finalmente, introduzcamos un nuevo concepto en nuestro análisis: la <strong>región de clasificación</strong> , representada por la gradiente de colores en nuestros gráficos y determinada por la frontera de decisión. Así como podemos modificar la ''rotación'' de esa frontera, también podemos desplazar la región de clasificación añadiendo una especie química adicional de concentración constante, conocida como <strong>bias</strong>."
                   data-en="Finally, let us introduce a new concept into our analysis: the <strong>classification region</strong>, represented by the color gradient in our plots and determined by the decision boundary. Just as we can modify the ''rotation'' of that boundary, we can also shift the classification region by adding an additional chemical species of constant concentration, known as the <strong>bias</strong>.">
                   Finalmente, introduzcamos un nuevo concepto en nuestro análisis: la <strong>región de clasificación</strong> , representada por la gradiente de colores en nuestros gráficos y determinada por la frontera de decisión. Así como podemos modificar la ''rotación'' de esa frontera, también podemos desplazar la región de clasificación añadiendo una especie química adicional de concentración constante, conocida como <strong>bias</strong>.
                </p>

            </div>

            <div class="cell cell-output" style="margin-bottom: 0.5rem; text-align: center;">
            <!-- Versión en español -->
                <iframe class="lang-img" data-lang="es"
                    src="Figura 4_LN4_esp.html"
                    width="70%" height="250"
                    style="border:none; display: block;"></iframe>

                <!-- Versión en inglés -->
                <iframe class="lang-img" data-lang="en"
                    src="Figura 4_LN4_esp.html"
                    width="70%" height="250"
                    style="border:none; display: none;"></iframe>
            </div>

            <div class="cell cell-markdown">

                <h2 style="color: var(--dark-purple);" data-es="Clasificadores no lineales"
                    data-en="Nonlinear Classifiers">
                    Clasificadores no lineales
                </h2>
                
                <p data-es="Un <strong>perceptrón multicapa</strong> extiende los clasificadores lineales al incorporar <strong>capas ocultas</strong>, lo que permite generar <strong>fronteras de decisión no lineales</strong>. En esta arquitectura, como se muestra en la Figura cada nodo calcula una salida a partir de sus entradas, y esas salidas alimentan a la siguiente capa."
                   data-en="A <strong>multilayer perceptron</strong> extends linear classifiers by incorporating <strong>hidden layers</strong>, allowing for the creation of <strong>nonlinear decision boundaries</strong>. In this architecture, as shown in the Figure, each node computes an output from its inputs, and those outputs feed into the next layer.">
                   Un <strong>perceptrón multicapa</strong> extiende los clasificadores lineales al incorporar <strong>capas ocultas</strong>, lo que permite generar <strong>fronteras de decisión no lineales</strong>. En esta arquitectura, como se muestra en la Figura cada nodo calcula una salida a partir de sus entradas, y esas salidas alimentan a la siguiente capa.
                </p>

                <div class="cell cell-markdown" style="display: flex; justify-content: center;">
                    <img src="Figura 5_LN4_esp.png" alt="Figura ES" class="lang-img" data-lang="es" style="max-width: 100%; height: auto;">
                    <img src="Figura 5_LN4_en.png" alt="Figure EN" class="lang-img" data-lang="en" style="max-width: 100%; height: auto; display: none;">
                </div>

                <p data-es="Para diseñar este tipo de clasificadores, debemos conectar la salida de un perceptron hacia la siguiente capa."
                   data-en="To design this type of classifier, we must connect the output of one perceptron to the next layer.">
                   Para diseñar este tipo de clasificadores, debemos conectar la salida de un perceptron hacia la siguiente capa.
                </p>

            </div>

            <div class="cell cell-output" style="margin-bottom: 0.5rem; text-align: center;">
            <!-- Versión en español -->
                <iframe class="lang-img" data-lang="es"
                    src="Figura 6_LN4_esp.html"
                    width="100%" height="250"
                    style="border:none; display: block;"></iframe>

                <!-- Versión en inglés -->
                <iframe class="lang-img" data-lang="en"
                    src="Figura 6_LN4_esp.html"
                    width="100%" height="250"
                    style="border:none; display: none;"></iframe>
            </div>

            <div class="cell cell-output" style="margin-bottom: 0.5rem; text-align: center;">
            <!-- Versión en español -->
                <iframe class="lang-img" data-lang="es"
                    src="Figura 7_LN4_esp.html"
                    width="100%" height="250"
                    style="border:none; display: block;"></iframe>

                <!-- Versión en inglés -->
                <iframe class="lang-img" data-lang="en"
                    src="Figura 7_LN4_esp.html"
                    width="100%" height="250"
                    style="border:none; display: none;"></iframe>
            </div>

            
            <div class="cell cell-markdown">

                <h3  data-es="Lecturas recomendadas"
                    data-en="Recommended Readings">
                    Lecturas recomendadas
                </h3>
                
                <p data-es="<strong>[1]</strong> Samaniego, C.C. et al. (2021) ‘Signaling-based neural networks for cellular computation’, 2021 American Control Conference (ACC), pp. 1883–1890. doi:10.23919/acc50511.2021.9482800."
                   data-en="<strong>[1]</strong> Samaniego, C.C. et al. (2021) ‘Signaling-based neural networks for cellular computation’, 2021 American Control Conference (ACC), pp. 1883–1890. doi:10.23919/acc50511.2021.9482800.">
                    <strong>[1]</strong> Samaniego, C.C. et al. (2021) ‘Signaling-based neural networks for cellular computation’, 2021 American Control Conference (ACC), pp. 1883–1890. doi:10.23919/acc50511.2021.9482800.
                </p>

                <p data-es="<strong>[2]</strong>  Samaniego, C.C. et al. (2024) ‘Neural networks built from enzymatic reactions can operate as linear and nonlinear classifiers’, 2024 IEEE 63rd Conference on Decision and Control (CDC), pp. 6292–6297. doi:10.1109/cdc56724.2024.10886454."
                   data-en="<strong>[2]</strong>  Samaniego, C.C. et al. (2024) ‘Neural networks built from enzymatic reactions can operate as linear and nonlinear classifiers’, 2024 IEEE 63rd Conference on Decision and Control (CDC), pp. 6292–6297. doi:10.1109/cdc56724.2024.10886454.">
                    <strong>[2]</strong>  Samaniego, C.C. et al. (2024) ‘Neural networks built from enzymatic reactions can operate as linear and nonlinear classifiers’, 2024 IEEE 63rd Conference on Decision and Control (CDC), pp. 6292–6297. doi:10.1109/cdc56724.2024.10886454.
                </p>

                <p data-es="<strong>[3]</strong> Chen, Z. et al. (2024) ‘A synthetic protein-level neural network in mammalian cells’, Science, 386(6727), pp. 1243–1250. doi:10.1126/science.add8468."
                   data-en="<strong>[3]</strong> Chen, Z. et al. (2024) ‘A synthetic protein-level neural network in mammalian cells’, Science, 386(6727), pp. 1243–1250. doi:10.1126/science.add8468.">
                    <strong>[3]</strong> Chen, Z. et al. (2024) ‘A synthetic protein-level neural network in mammalian cells’, Science, 386(6727), pp. 1243–1250. doi:10.1126/science.add8468.
                </p>

                <p data-es="<strong>[4]</strong> Nakamura, E. et al. (2025) Sequestration-based neural networks that operate out of equilibrium [Preprint]. doi:10.1101/2025.05.16.654484."
                   data-en="<strong>[4]</strong> Nakamura, E. et al. (2025) Sequestration-based neural networks that operate out of equilibrium [Preprint]. doi:10.1101/2025.05.16.654484.">
                    <strong>[4]</strong> Nakamura, E. et al. (2025) Sequestration-based neural networks that operate out of equilibrium [Preprint]. doi:10.1101/2025.05.16.654484.
                </p>


            </div>
            

        </div>
    </section>

    <!-- Footer - exactamente igual a tu index -->
    <footer class="footer">
        <div class="container">
            <p data-es="&copy; 2025 EBCP Latam. Preparado por el Laboratorio del Dr. Christian Cuba Samaniego"
               data-en="&copy; 2025 EBCP Latam. Prepared by Dr. Christian Cuba Samaniego's Laboratory">
               &copy; 2025 EBCP Latam. Preparado por el Laboratorio del Dr. Christian Cuba Samaniego
            </p>
        </div>
    </footer>

    <!-- Scripts -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/components/prism-core.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.29.0/plugins/autoloader/prism-autoloader.min.js"></script>

    <!-- JavaScript exactamente igual a tu index -->
    <script>
        class LanguageManager {
            constructor() {
                this.currentLang = localStorage.getItem('selectedLanguage') || 'es';
                this.init();
            }

            init() {
                this.setupEventListeners();
                this.setLanguage(this.currentLang);
            }

            setupEventListeners() {
                const langButtons = document.querySelectorAll('.lang-btn');
                langButtons.forEach(btn => {
                    btn.addEventListener('click', (e) => {
                        const lang = e.target.getAttribute('data-lang');
                        this.setLanguage(lang);
                    });
                });
            }

            setLanguage(lang) {
                this.currentLang = lang;
                localStorage.setItem('selectedLanguage', lang);
                
                document.getElementById('html-root').setAttribute('lang', lang);
                
                const elements = document.querySelectorAll('[data-es][data-en]');
                elements.forEach(element => {
                    const text = element.getAttribute(`data-${lang}`);
                    if (text) {
                        element.innerHTML = text;
                    }
                });


                if (window.MathJax) {
                    MathJax.typesetPromise();
                }

                document.querySelectorAll('.lang-btn').forEach(btn => {
                    btn.classList.remove('active');
                    if (btn.getAttribute('data-lang') === lang) {
                        btn.classList.add('active');
                    }
                });
                
                // Mostrar/ocultar bloques de código por idioma
                document.querySelectorAll('.lang-block').forEach(block => {
                    const blockLang = block.getAttribute('data-lang');
                    block.style.display = (blockLang === lang) ? 'block' : 'none';
                });

                // Mostrar/ocultar imágenes según idioma
                document.querySelectorAll('.lang-img').forEach(img => {
                    const imgLang = img.getAttribute('data-lang');
                    img.style.display = (imgLang === lang) ? 'block' : 'none';
                });

                const titles = {
                    es: 'Redes Neuronales Biomoleculares - EBCP Latam 2025',
                    en: 'Biomolecular Neural Networks - EBCP Latam 2025'
                };
                document.title = titles[lang];
            }
        }

        document.addEventListener('DOMContentLoaded', () => {
            new LanguageManager();
        });

    </script>
    <script>
        if (window.MathJax) {
            MathJax.typesetPromise();
        }
    </script>
</body>
</html>